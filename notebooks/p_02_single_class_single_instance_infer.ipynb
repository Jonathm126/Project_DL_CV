{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision.io import read_video\n",
    "from torchvision.transforms import v2 as T\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "\n",
    "\n",
    "# paths\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# set paths\n",
    "dirpath = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(dirpath)\n",
    "\n",
    "# my imports\n",
    "from models.SoSi_detection import SoSiDetectionModel  # noqa: E402\n",
    "from utils.plot_utils import inverse_transform_bbox  # noqa: E402\n",
    "\n",
    "\n",
    "# the lifesaver\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# torch setup\n",
    "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'p02_model_Mar-09_18-15-05.pth' # good result using MSE K=1\n",
    "# model_file = 'p02_model_Mar-09_19-30-47.pth' # smooth L1 and K=4\n",
    "# model_file = 'p02_model_Mar-09_20-09-10.pth' # ciou and k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model_path = 'models\\\\model_savepoints\\\\'\n",
    "model_path = os.path.join(dirpath, model_path, model_file)\n",
    "\n",
    "# build and load model\n",
    "model = SoSiDetectionModel(final_head_conv_depth = 128)  \n",
    "sucess = model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "print(sucess)\n",
    "model.to(device).eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get video file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vid_name = 'kittens_video.mp4'\n",
    "vid_name = 'cats_wild.mp4'\n",
    "# vid_name = 'cats_forest.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file = os.path.join(dirpath, f'inference\\\\{vid_name}')\n",
    "video_out_file = os.path.join(dirpath, f'inference\\\\{vid_name[:-4]}_{model_file[:-4]}.mp4')\n",
    "\n",
    "# video params\n",
    "video_h, video_w = 360, 640\n",
    "video_fps = 30\n",
    "\n",
    "# calculate end time and time jump for inference\n",
    "video_start_sec = 90\n",
    "video_end_sec = 90+120\n",
    "batch_size = 256 \n",
    "video_jump = batch_size / video_fps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build video writer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_writer = cv2.VideoWriter(video_out_file, fourcc, video_fps, (video_w, video_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Transforms for inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model transforms\n",
    "backbone_transforms = model.backbone_transforms()\n",
    "\n",
    "# pre-procesing transform\n",
    "preprocess = T.Compose([\n",
    "    # standard transforms - resizing and center cropping for 1:1 aspect ratio and 224 size\n",
    "    T.Resize(size = backbone_transforms.resize_size, interpolation = backbone_transforms.interpolation),\n",
    "    T.CenterCrop(size=backbone_transforms.crop_size),\n",
    "    \n",
    "    # standard transforms - normalizing\n",
    "    T.ToImage(),\n",
    "    T.ToDtype(torch.float32, scale=True),\n",
    "    T.Normalize(mean = backbone_transforms.mean, std = backbone_transforms.std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_current_start = video_start_sec\n",
    "\n",
    "# loop on frames\n",
    "while video_current_start < video_end_sec:\n",
    "    # read frames\n",
    "    frames, _ ,_  = read_video(filename = video_file, \n",
    "                                    start_pts = video_current_start, end_pts = min(video_current_start + video_jump, video_end_sec),\n",
    "                                    output_format=\"TCHW\", pts_unit = 'sec')\n",
    "    video_current_start += video_jump\n",
    "    frames = frames.to(device)\n",
    "    \n",
    "    # if no frames read, break the loop\n",
    "    if frames.numel() == 0:  \n",
    "        break\n",
    "    \n",
    "    # preprocess\n",
    "    frames_preproces = preprocess(frames).to(device)\n",
    "    \n",
    "    # infer\n",
    "    pred_boxes, pred_labels_logits = model(frames_preproces)\n",
    "    \n",
    "    # compute the labels\n",
    "    confidences = torch.sigmoid(pred_labels_logits).squeeze()\n",
    "    pred_labels_str = [\n",
    "            f\"cat {conf:.2f}\" if conf > 0.3 else \"none\"\n",
    "            for conf in confidences.tolist()\n",
    "        ]\n",
    "    \n",
    "    # scale the bbox to video scale\n",
    "    bbox_resized = inverse_transform_bbox(pred_boxes, video_w, video_h)\n",
    "    \n",
    "    # append all frames and write to disk\n",
    "    for idx in range(len(frames)):\n",
    "        # false label - do not print\n",
    "        if confidences[idx] <= cutoff:  \n",
    "            video_frame = frames[idx].cpu()\n",
    "            \n",
    "        # true label - print bbox\n",
    "        else:\n",
    "            image_with_boxes = draw_bounding_boxes(frames[idx], bbox_resized[idx,:], fill=False, colors=\"red\", width=3, \n",
    "                                            labels=[pred_labels_str[idx]], font_size=25, font='verdana.ttf')\n",
    "            # frame_with_bbox_pil = F.to_pil_image(image_with_boxes)\n",
    "            video_frame = (image_with_boxes)\n",
    "        \n",
    "        # convert it to a NumPy array with shape [H, W, C]\n",
    "        frame_np = video_frame.permute(1, 2, 0).cpu().numpy()\n",
    "        \n",
    "        # convert to bgr\n",
    "        frame_np = frame_np[..., [2, 1, 0]]\n",
    "        \n",
    "        # if frame is normalized, convert to uint8\n",
    "        if frame_np.dtype != np.uint8:\n",
    "            frame_np = (255 * frame_np).clip(0, 255).astype(np.uint8)\n",
    "        \n",
    "        # Write the frame to the video file.\n",
    "        video_writer.write(frame_np)\n",
    "\n",
    "video_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video re-encode to compress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with clang version 17.0.1\n",
      "  configuration: --prefix=/d/bld/ffmpeg_1696213838503/_h_env/Library --cc=clang.exe --cxx=clang++.exe --nm=llvm-nm --ar=llvm-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --ld=lld-link --target-os=win64 --enable-cross-compile --toolchain=msvc --host-cc=clang.exe --extra-libs=ucrt.lib --extra-libs=vcruntime.lib --extra-libs=oldnames.lib --strip=llvm-strip --disable-stripping --host-extralibs= --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/d/bld/ffmpeg_1696213838503/_build_env/Library/bin/pkg-config\n",
      "  libavutil      57. 28.100 / 57. 28.100\n",
      "  libavcodec     59. 37.100 / 59. 37.100\n",
      "  libavformat    59. 27.100 / 59. 27.100\n",
      "  libavdevice    59.  7.100 / 59.  7.100\n",
      "  libavfilter     8. 44.100 /  8. 44.100\n",
      "  libswscale      6.  7.100 /  6.  7.100\n",
      "  libswresample   4.  7.100 /  4.  7.100\n",
      "  libpostproc    56.  6.100 / 56.  6.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'g:\\My Drive\\Github\\Project_DL_CV\\inference\\cats_wild_p02_model_Mar-09_18-15-05.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.76.100\n",
      "  Duration: 00:02:00.37, start: 0.000000, bitrate: 5935 kb/s\n",
      "  Stream #0:0[0x1](und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 640x360 [SAR 1:1 DAR 16:9], 5934 kb/s, 30 fps, 30 tbr, 15360 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0000022D68A21740] using SAR=1/1\n",
      "[libx264 @ 0000022D68A21740] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0000022D68A21740] profile High, level 3.0, 4:2:0, 8-bit\n",
      "[libx264 @ 0000022D68A21740] 264 - core 164 r3095 baee400 - H.264/MPEG-4 AVC codec - Copyleft 2003-2022 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=11 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=abr mbtree=1 bitrate=1000 ratetol=1.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'g:\\My Drive\\Github\\Project_DL_CV\\inference\\cats_wild_p02_model_Mar-09_18-15-05_compressed.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 640x360 [SAR 1:1 DAR 16:9], q=2-31, 1000 kb/s, 30 fps, 15360 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc59.37.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/1000000 buffer size: 0 vbv_delay: N/A\n",
      "frame=    1 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    \n",
      "frame=  276 fps=0.0 q=32.0 size=     768kB time=00:00:07.26 bitrate= 865.8kbits/s speed=  14x    \n",
      "frame=  538 fps=528 q=33.0 size=    1792kB time=00:00:16.00 bitrate= 917.5kbits/s speed=15.7x    \n",
      "frame=  820 fps=539 q=34.0 size=    3072kB time=00:00:25.40 bitrate= 990.8kbits/s speed=16.7x    \n",
      "frame= 1129 fps=558 q=31.0 size=    4096kB time=00:00:35.70 bitrate= 939.9kbits/s speed=17.6x    \n",
      "frame= 1408 fps=557 q=30.0 size=    5120kB time=00:00:45.00 bitrate= 932.1kbits/s speed=17.8x    \n",
      "frame= 1660 fps=548 q=30.0 size=    6144kB time=00:00:53.40 bitrate= 942.5kbits/s speed=17.6x    \n",
      "frame= 1949 fps=551 q=30.0 size=    7168kB time=00:01:03.03 bitrate= 931.6kbits/s speed=17.8x    \n",
      "frame= 2217 fps=549 q=30.0 size=    8448kB time=00:01:11.96 bitrate= 961.6kbits/s speed=17.8x    \n",
      "frame= 2475 fps=546 q=30.0 size=    9472kB time=00:01:20.56 bitrate= 963.1kbits/s speed=17.8x    \n",
      "frame= 2715 fps=539 q=31.0 size=   10752kB time=00:01:28.56 bitrate= 994.5kbits/s speed=17.6x    \n",
      "frame= 2961 fps=533 q=31.0 size=   11776kB time=00:01:36.76 bitrate= 996.9kbits/s speed=17.4x    \n",
      "frame= 3117 fps=272 q=31.0 size=   12288kB time=00:01:41.96 bitrate= 987.2kbits/s speed=8.89x    \n",
      "frame= 3390 fps=283 q=31.0 size=   13568kB time=00:01:51.06 bitrate=1000.7kbits/s speed=9.26x    \n",
      "frame= 3611 fps=290 q=-1.0 Lsize=   14731kB time=00:02:00.26 bitrate=1003.4kbits/s speed=9.64x    \n",
      "video:14695kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.243683%\n",
      "[libx264 @ 0000022D68A21740] frame I:15    Avg QP:23.98  size: 39683\n",
      "[libx264 @ 0000022D68A21740] frame P:1836  Avg QP:26.82  size:  6393\n",
      "[libx264 @ 0000022D68A21740] frame B:1760  Avg QP:32.75  size:  1542\n",
      "[libx264 @ 0000022D68A21740] consecutive B-frames: 30.6%  9.6% 10.6% 49.2%\n",
      "[libx264 @ 0000022D68A21740] mb I  I16..4:  1.0% 84.1% 14.8%\n",
      "[libx264 @ 0000022D68A21740] mb P  I16..4:  0.4%  4.4%  1.2%  P16..4: 43.6% 19.7% 12.0%  0.0%  0.0%    skip:18.6%\n",
      "[libx264 @ 0000022D68A21740] mb B  I16..4:  0.1%  0.4%  0.2%  B16..8: 46.4%  5.5%  1.2%  direct: 1.3%  skip:44.9%  L0:44.8% L1:46.3% BI: 8.9%\n",
      "[libx264 @ 0000022D68A21740] final ratefactor: 25.10\n",
      "[libx264 @ 0000022D68A21740] 8x8 transform intra:73.0% inter:63.0%\n",
      "[libx264 @ 0000022D68A21740] coded y,uvDC,uvAC intra: 81.6% 49.2% 12.5% inter: 19.4% 9.5% 3.1%\n",
      "[libx264 @ 0000022D68A21740] i16 v,h,dc,p: 29% 40% 13% 19%\n",
      "[libx264 @ 0000022D68A21740] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 27% 19% 22%  4%  5%  5%  7%  5%  7%\n",
      "[libx264 @ 0000022D68A21740] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 33% 20% 14%  4%  6%  5%  7%  4%  6%\n",
      "[libx264 @ 0000022D68A21740] i8c dc,h,v,p: 52% 25% 21%  2%\n",
      "[libx264 @ 0000022D68A21740] Weighted P-Frames: Y:4.0% UV:1.5%\n",
      "[libx264 @ 0000022D68A21740] ref P L0: 68.4% 18.4%  9.9%  3.2%  0.2%\n",
      "[libx264 @ 0000022D68A21740] ref B L0: 88.4%  9.6%  2.0%\n",
      "[libx264 @ 0000022D68A21740] ref B L1: 96.2%  3.8%\n",
      "[libx264 @ 0000022D68A21740] kb/s:1000.06\n"
     ]
    }
   ],
   "source": [
    "command = f'ffmpeg -i \"{video_out_file}\" -c:v libx264 -b:v 1M \"{video_out_file[:-4]}_compressed.mp4\"' # \"{video_out_file}\"\n",
    "!{command}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
